{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Training</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture and loss functions inspired and adapted from https://github.com/ternaus/kaggle_dstl_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import merge, Input, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import binary_crossentropy\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from PIL import Image\n",
    "\n",
    "from generator import myGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the gpu id\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function used is a sum of binary crossentropy and jaccard index as defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-12\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    return -K.log(jaccard_coef(y_true, y_pred)) + binary_crossentropy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture inspired from the U-Net paper (https://arxiv.org/pdf/1505.04597.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(num_channels, img_rows, img_cols):\n",
    "    \n",
    "    inputs = Input((img_rows, img_cols, num_channels))\n",
    "    conv1 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, padding='same', kernel_initializer ='he_uniform', activation = 'elu')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, 3, padding='same', kernel_initializer ='he_uniform', activation = 'elu')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(512, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Conv2D(256, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv9)\n",
    "    crop9 = Cropping2D(cropping=((16, 16), (16, 16)))(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    adam = Adam(lr=1e-3)\n",
    "    model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we random sample tiles of 256x256 from the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 16\n",
    "train_steps = 10000//batch_size\n",
    "val_steps = 1000//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:33: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:39: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:51: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(3, img_size, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path to your data folders \n",
    "train = [os.path.join('/root/data/hackathon/building_massa_dataset/images/train/', f ) for f in os.listdir('/root/data/hackathon/building_massa_dataset/images/train/') if f.endswith('.tiff')]\n",
    "val = [os.path.join('/root/data/hackathon/building_massa_dataset/images/valid/', f ) for f in os.listdir('/root/data/hackathon/building_massa_dataset/images/valid/') if f.endswith('.tiff')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the generators\n",
    "train_generator = myGenerator(train, train_steps, batch_size, (img_size, img_size, 3))\n",
    "validation_generator = myGenerator(val, val_steps, batch_size, (img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_jaccard_coef_int',\n",
    "                              factor=0.5, \n",
    "                              patience=1, \n",
    "                              min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('/root/data/hackathon/thomas_augmentation_weights_{epoch:02d}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model should converge relatively fast. One epoch takes about 10 min on a single GTX TITAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 557s 892ms/step - loss: 3.1881 - binary_crossentropy: 0.9919 - jaccard_coef_int: 0.3455 - val_loss: 2.4198 - val_binary_crossentropy: 0.7634 - val_jaccard_coef_int: 0.3477\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 563s 901ms/step - loss: 2.3026 - binary_crossentropy: 0.9121 - jaccard_coef_int: 0.4437 - val_loss: 1.9446 - val_binary_crossentropy: 0.7331 - val_jaccard_coef_int: 0.4581\n",
      "Epoch 3/50\n",
      "301/625 [=============>................] - ETA: 4:33 - loss: 2.1215 - binary_crossentropy: 0.8946 - jaccard_coef_int: 0.4773"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
