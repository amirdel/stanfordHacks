{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from keras.layers import merge, Input, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from keras.backend import binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "backend = tf\n",
    "\n",
    "def focal(alpha=0.25, gamma=5.0):\n",
    "    def _focal(y_true, y_pred):\n",
    "        labels         = y_true\n",
    "        classification = y_pred\n",
    "\n",
    "        # compute the focal loss\n",
    "        alpha_factor = keras.backend.ones_like(labels) * alpha\n",
    "        alpha_factor = backend.where(keras.backend.equal(labels, 1), alpha_factor, 1 - alpha_factor)\n",
    "        focal_weight = backend.where(keras.backend.equal(labels, 1), 1 - classification, classification)\n",
    "        focal_weight = alpha_factor * focal_weight ** gamma\n",
    "\n",
    "        cls_loss = focal_weight * keras.backend.binary_crossentropy(labels, classification)\n",
    "\n",
    "#         # filter out \"ignore\" anchors\n",
    "#         anchor_state = keras.backend.max(labels, axis=2)  # -1 for ignore, 0 for background, 1 for object\n",
    "#         indices      = backend.where(keras.backend.not_equal(anchor_state, -1))\n",
    "#         cls_loss     = backend.gather_nd(cls_loss, indices)\n",
    "\n",
    "#         # compute the normalizer: the number of positive anchors\n",
    "#         normalizer = backend.where(keras.backend.equal(anchor_state, 1))\n",
    "#         normalizer = keras.backend.cast(keras.backend.shape(normalizer)[0], keras.backend.floatx())\n",
    "#         normalizer = keras.backend.maximum(1.0, normalizer)\n",
    "\n",
    "#         return keras.backend.sum(cls_loss) / normalizer\n",
    "        return cls_loss\n",
    "\n",
    "    return _focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    return -K.log(jaccard_coef(y_true, y_pred)) + binary_crossentropy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(num_channels, img_rows, img_cols):\n",
    "    \n",
    "    inputs = Input((img_rows, img_cols, num_channels))\n",
    "    conv1 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = BatchNormalization(mode=0, axis=1)(conv1)\n",
    "#     conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "    conv1 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = BatchNormalization(mode=0, axis=1)(conv1)\n",
    "#     conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    print pool1.shape\n",
    "    conv2 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    # conv2 = BatchNormalization(mode=0, axis=1)(conv2)\n",
    "    # conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "    conv2 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    # conv2 = BatchNormalization(mode=0, axis=1)(conv2)\n",
    "    # conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    # conv3 = BatchNormalization(mode=0, axis=1)(conv3)\n",
    "    # conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "    conv3 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    # conv3 = BatchNormalization(mode=0, axis=1)(conv3)\n",
    "    # conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, padding='same', kernel_initializer ='he_uniform', activation = 'elu')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    # conv4 = BatchNormalization(mode=0, axis=1)(conv4)\n",
    "    # conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "    conv4 = Conv2D(256, 3, padding='same', kernel_initializer ='he_uniform', activation = 'elu')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    # conv4 = BatchNormalization(mode=0, axis=1)(conv4)\n",
    "    # conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(512, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    # conv5 = BatchNormalization(mode=0, axis=1)(conv5)\n",
    "    # conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "    conv5 = Conv2D(512, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    # conv5 = BatchNormalization(mode=0, axis=1)(conv5)\n",
    "    # conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Conv2D(256, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    # conv6 = BatchNormalization(mode=0, axis=1)(conv6)\n",
    "    # conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "    conv6 = Conv2D(256, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    # conv6 = BatchNormalization(mode=0, axis=1)(conv6)\n",
    "    # conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    # conv7 = BatchNormalization(mode=0, axis=1)(conv7)\n",
    "    # conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "    conv7 = Conv2D(128, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    # conv7 = BatchNormalization(mode=0, axis=1)(conv7)\n",
    "    # conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "#     conv8 = BatchNormalization(mode=0, axis=1)(conv8)\n",
    "#     conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "    conv8 = Conv2D(64, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "#     conv8 = BatchNormalization(mode=0, axis=1)(conv8)\n",
    "#     conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "#     conv9 = BatchNormalization(mode=0, axis=1)(conv9)\n",
    "#     conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "    conv9 = Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation = 'elu')(conv9)\n",
    "    crop9 = Cropping2D(cropping=((16, 16), (16, 16)))(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "#     conv9 = BatchNormalization(mode=0, axis=1)(crop9)\n",
    "#     conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    adam = Adam(lr=1e-3)\n",
    "    model.compile(adam, loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 128, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:53: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:63: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:73: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:83: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(3, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_train = [np.expand_dims(np.array(Image.open('/root/data/hackathon/building_massa_dataset/images/train/22678915_15.tiff')), axis=0)]\n",
    "# imgs_mask_train = [np.expand_dims(np.array(Image.open('/root/data/hackathon/building_massa_dataset/labels/train/22678915_15.tif'))[6:-6, 6:-6], axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 10000//batch_size\n",
    "val_steps = 1000//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(file_paths, steps_per_epoch, BATCH_SIZE, INPUT_SHAPE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2]))\n",
    "        y_batch = np.empty((BATCH_SIZE, INPUT_SHAPE[0], INPUT_SHAPE[1], 1))\n",
    "        for (ind, j) in enumerate(range(i*BATCH_SIZE, (i+1)*BATCH_SIZE)):\n",
    "            # pick a random image\n",
    "            f = np.random.choice(file_paths)\n",
    "            # random_x = np.random.randint(0, 1500-img_size)\n",
    "            # random_y = np.random.randint(0, 1500-img_size)\n",
    "            random_x = 0\n",
    "            random_y = 0\n",
    "            x_batch[ind,...] = np.array(Image.open(f))[random_x:random_x+img_size, random_y:random_y+img_size, :]\n",
    "            # pick the corresponding mask\n",
    "            ftruth = f.replace('images', 'labels')\n",
    "            ftruth = ftruth[:-1]\n",
    "            mask = np.expand_dims(np.array(Image.open(ftruth))[random_x:random_x+img_size, random_y:random_y+img_size, 0], axis=2)\n",
    "            # mask = np.array(Image.open(ftruth))[random_x:random_x+img_size, random_y:random_y+img_size, :]\n",
    "            mask[mask==255]=1\n",
    "            y_batch[ind,...] = mask\n",
    "        # x_batch = seq.augment_images(x_batch)\n",
    "        i += 1\n",
    "        if i >= steps_per_epoch:\n",
    "            i = 0\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [os.path.join('/root/data/hackathon/building_massa_dataset/images/train/', f ) for f in os.listdir('/root/data/hackathon/building_massa_dataset/images/train/') if f.endswith('.tiff')][:1]\n",
    "val = [os.path.join('/root/data/hackathon/building_massa_dataset/images/valid/', f ) for f in os.listdir('/root/data/hackathon/building_massa_dataset/images/valid/') if f.endswith('.tiff')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = myGenerator(train, train_steps, batch_size, (img_size, img_size, 3))\n",
    "validation_generator = myGenerator(val, val_steps, batch_size, (img_size, img_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.5, \n",
    "                              patience=1, \n",
    "                              min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  9/625 [..............................] - ETA: 10:31 - loss: 2.4075 - binary_crossentropy: 0.9330 - jaccard_coef_int: 0.3471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd0b8e63fa5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         validation_steps=val_steps)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start training\n",
    "history = model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=1,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(imgs_train, \n",
    "#                     imgs_mask_train, \n",
    "#                     batch_size=4, \n",
    "#                     nb_epoch=10, \n",
    "#                     verbose=1,\n",
    "#                     validation_split=0.2, \n",
    "#                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(np.expand_dims(np.array(Image.open(train[0]))[:256, :256, :], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(test>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb20e972310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "truc = test[0,...,0]\n",
    "plt.imshow(truc)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru = test[0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru[tru>0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
